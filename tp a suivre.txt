Workshop MLOps avec Azure - Guide Pratique
1 Introduction
1.1 Bienvenue !
Ce workshop vous guidera √† travers le d√©ploiement complet d‚Äôun mod√®le de Machine Learning en production sur Microsoft Azure. Vous allez construire une API de pr√©diction de d√©faillance client (churn) et la d√©ployer sur le cloud avec toutes les bonnes pratiques MLOps.

1.2 Objectifs d‚ÄôApprentissage
√Ä la fin de ce workshop, vous serez capable de :

Entra√Æner et sauvegarder un mod√®le ML avec MLflow
Cr√©er une API REST avec FastAPI
Conteneuriser une application avec Docker
D√©ployer sur Azure Container Apps
Mettre en place un pipeline CI/CD avec GitHub Actions
Monitorer votre application en production
D√©tecter le data drift
1.3 Le Projet : Bank Churn Prediction
Contexte : Une banque souhaite pr√©dire quels clients risquent de partir pour proposer des actions de r√©tention.

Dataset : 10 features (√¢ge, score cr√©dit, solde, etc.) + 1 target (Exited : 0/1)

Mod√®le : Random Forest Classifier

Livrable : API REST d√©ploy√©e sur Azure, accessible publiquement

1.4 Architecture Finale
Flux de d√©ploiement :

Code GitHub ‚Üí GitHub Actions ‚Üí Docker Build ‚Üí Azure Container Registry ‚Üí Azure Container Apps ‚Üí Internet

2 Pr√©paration de l‚ÄôEnvironnement
2.1 Logiciels Requis
Obligatoire :

Python 3.9+ : https://www.python.org/downloads/
Visual Studio Code : https://code.visualstudio.com/
Git : https://git-scm.com/downloads
Docker Desktop : https://www.docker.com/products/docker-desktop
Azure CLI : https://docs.microsoft.com/cli/azure/install-azure-cli
Comptes √† cr√©er :

Compte GitHub : https://github.com/signup
Azure for Students (100$) : https://azure.microsoft.com/students
2.2 V√©rification de l‚ÄôInstallation
Ouvrez un terminal et testez :

# Python
python --version
# Doit afficher Python 3.9.x ou superieur

# Git
git --version

# Docker
docker --version
docker ps

# Azure CLI
az --version

2.3 Configuration Initiale
2.3.1 Configuration Git
git config --global user.name "Votre Nom"
git config --global user.email "votre.email@example.com"

2.3.2 Connexion √† Azure
# Se connecter a Azure
az login

# Verifier l'abonnement
az account show

# Si vous avez plusieurs abonnements, selectionner celui de Students
az account set --subscription "Azure for Students"

3 Module 1 : Entra√Ænement du Mod√®le
3.1 Objectif
Entra√Æner un mod√®le Random Forest pour pr√©dire le churn et le sauvegarder avec MLflow.

3.2 Pr√©paration du Projet
# Creer le dossier du projet
mkdir bank-churn-mlops
cd bank-churn-mlops

# Creer un environnement virtuel
python -m venv venv

# Activer l'environnement
# Windows :
venv\Scripts\activate
# Mac/Linux :
source venv/bin/activate

# Creer la structure
mkdir -p data model app tests
touch requirements.txt

3.3 Fichier requirements.txt
Cr√©ez le fichier requirements.txt avec le contenu suivant :

# API Framework
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0

# Machine Learning
scikit-learn==1.3.2
pandas==2.1.3
numpy==1.26.2
joblib==1.3.2

# MLflow
mlflow==2.8.1

# Testing
pytest==7.4.3
pytest-cov==4.1.0
httpx==0.25.2

# Utilities
python-multipart==0.0.6
requests==2.31.0
Puis installez les d√©pendances :

pip install -r requirements.txt

3.4 T√©l√©chargement du Dataset
Cr√©ez un dataset synth√©tique :

# generate_data.py
import pandas as pd
import numpy as np

np.random.seed(42)
n_samples = 10000

data = {
    'CreditScore': np.random.randint(300, 850, n_samples),
    'Age': np.random.randint(18, 80, n_samples),
    'Tenure': np.random.randint(0, 11, n_samples),
    'Balance': np.random.uniform(0, 200000, n_samples),
    'NumOfProducts': np.random.randint(1, 5, n_samples),
    'HasCrCard': np.random.choice([0, 1], n_samples),
    'IsActiveMember': np.random.choice([0, 1], n_samples),
    'EstimatedSalary': np.random.uniform(20000, 150000, n_samples),
    'Geography_Germany': np.random.choice([0, 1], n_samples),
    'Geography_Spain': np.random.choice([0, 1], n_samples),
}

# Target : plus de chance de partir si inactif, peu de produits, etc.
churn_prob = (
    (1 - data['IsActiveMember']) * 0.3 +
    (data['NumOfProducts'] == 1) * 0.2 +
    (data['Age'] > 60) * 0.15 +
    (data['Balance'] == 0) * 0.25
)
data['Exited'] = (np.random.random(n_samples) < churn_prob).astype(int)

df = pd.DataFrame(data)
df.to_csv('data/bank_churn.csv', index=False)
print(f"Dataset cree : {len(df)} lignes")
print(f"Taux de churn : {df['Exited'].mean():.2%}")

3.5 Script d‚ÄôEntra√Ænement
Cr√©ez le fichier train_model.py :

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score,
    f1_score, 
    roc_auc_score,
    confusion_matrix
)
import joblib
import mlflow
import mlflow.sklearn
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration MLflow
mlflow.set_tracking_uri("./mlruns")
mlflow.set_experiment("bank-churn-prediction")

print("Chargement des donnees...")
df = pd.read_csv("data/bank_churn.csv")

print(f"Dataset : {len(df)} lignes, {len(df.columns)} colonnes")
print(f"Taux de churn : {df['Exited'].mean():.2%}")

# Separation features/target
X = df.drop('Exited', axis=1)
y = df['Exited']

# Split train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTrain : {len(X_train)} lignes")
print(f"Test : {len(X_test)} lignes")

# Entrainement avec MLflow tracking
print("\nEntrainement du modele...")
with mlflow.start_run(run_name="random-forest-v1"):
    
    # Parametres du modele
    params = {
        'n_estimators': 100,
        'max_depth': 10,
        'min_samples_split': 5,
        'random_state': 42
    }
    
    # Entrainement
    model = RandomForestClassifier(**params)
    model.fit(X_train, y_train)
    
    # Predictions
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    # Calcul des metriques
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_proba)
    
    # Log des parametres et metriques dans MLflow
    mlflow.log_params(params)
    mlflow.log_metrics({
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "roc_auc": auc
    })
    
    # Creation et sauvegarde de la matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Matrice de Confusion')
    plt.ylabel('Vraie Classe')
    plt.xlabel('Classe Predite')
    plt.savefig('confusion_matrix.png')
    mlflow.log_artifact('confusion_matrix.png')
    plt.close()
    
    # Feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance['feature'], feature_importance['importance'])
    plt.xlabel('Importance')
    plt.title('Feature Importance')
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    mlflow.log_artifact('feature_importance.png')
    plt.close()
    
    # Enregistrement du modele dans MLflow
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="bank-churn-classifier"
    )
    
    # Sauvegarde locale du modele
    joblib.dump(model, "model/churn_model.pkl")
    
    # Tags
    mlflow.set_tags({
        "environment": "development",
        "model_type": "RandomForest",
        "task": "binary_classification"
    })
    
    # Affichage des resultats
    print("\n" + "="*50)
    print("RESULTATS DE L'ENTRAINEMENT")
    print("="*50)
    print(f"Accuracy  : {accuracy:.4f}")
    print(f"Precision : {precision:.4f}")
    print(f"Recall    : {recall:.4f}")
    print(f"F1 Score  : {f1:.4f}")
    print(f"ROC AUC   : {auc:.4f}")
    print("="*50)
    
    print(f"\nModele sauvegarde dans : model/churn_model.pkl")
    print(f"MLflow UI : mlflow ui --port 5000")

3.6 Ex√©cution
# Lancer l'entrainement
python train_model.py

# Voir les resultats dans MLflow UI
mlflow ui --port 5000
# Ouvrir http://localhost:5000 dans votre navigateur

3.7 Checkpoint
Validation Module 1
Avant de passer au module suivant, v√©rifiez que :

Le mod√®le est entra√Æn√© avec une accuracy > 0.75
Le fichier model/churn_model.pkl existe
MLflow UI affiche votre exp√©rience
Vous comprenez les m√©triques obtenues
4 Module 2 : Cr√©ation de l‚ÄôAPI avec FastAPI
4.1 Objectif
Cr√©er une API REST qui expose le mod√®le via des endpoints HTTP.

4.2 Structure du Code API
bank-churn-mlops/
|-- app/
|   |-- __init__.py
|   |-- main.py
|   |-- models.py
|   +-- utils.py
|-- model/
|   +-- churn_model.pkl
|-- tests/
|   +-- test_api.py
|-- requirements.txt
+-- README.md
4.3 Fichier app/models.py
D√©finition des sch√©mas de donn√©es avec Pydantic :

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import joblib
import numpy as np
import logging
import os
import json
import glob
import traceback
from pathlib import Path

from opencensus.ext.azure.log_exporter import AzureLogHandler

from app.models import CustomerFeatures, PredictionResponse, HealthResponse
from app.drift_detect import detect_drift


# ============================================================
# LOGGING & APPLICATION INSIGHTS
# ============================================================

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("bank-churn-api")

APPINSIGHTS_CONN = os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
if APPINSIGHTS_CONN:
    handler = AzureLogHandler(connection_string=APPINSIGHTS_CONN)
    logger.addHandler(handler)
    logger.info("app_startup", extra={
        "custom_dimensions": {
            "event_type": "startup",
            "status": "application_insights_connected"
        }
    })
else:
    logger.warning("app_startup", extra={
        "custom_dimensions": {
            "event_type": "startup",
            "status": "application_insights_not_configured"
        }
    })


# ============================================================
# FASTAPI INIT
# ============================================================

app = FastAPI(
    title="Bank Churn Prediction API",
    description="API de pr√©diction et monitoring du churn client",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

MODEL_PATH = os.getenv("MODEL_PATH", "model/churn_model.pkl")
model = None


@app.on_event("startup")
async def load_model():
    global model
    try:
        model = joblib.load(MODEL_PATH)
        logger.info("model_loaded", extra={
            "custom_dimensions": {
                "event_type": "model_load",
                "model_path": MODEL_PATH,
                "status": "success"
            }
        })
    except Exception as e:
        logger.error("model_load_failed", extra={
            "custom_dimensions": {
                "event_type": "model_load",
                "error": str(e)
            }
        })
        model = None


# ============================================================
# GENERAL ENDPOINTS
# ============================================================

@app.get("/", tags=["General"])
def root():
    return {
        "message": "Bank Churn Prediction API",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs"
    }


@app.get("/health", response_model=HealthResponse)
def health():
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")
    return {"status": "healthy", "model_loaded": True}


# ============================================================
# PREDICTION ENDPOINTS
# ============================================================

@app.post("/predict", response_model=PredictionResponse)
def predict(features: CustomerFeatures):

    if model is None:
        raise HTTPException(status_code=503, detail="Model unavailable")

    try:
        input_data = np.array([[  
            features.CreditScore,
            features.Age,
            features.Tenure,
            features.Balance,
            features.NumOfProducts,
            features.HasCrCard,
            features.IsActiveMember,
            features.EstimatedSalary,
            features.Geography_Germany,
            features.Geography_Spain
        ]])

        proba = float(model.predict_proba(input_data)[0][1])
        prediction = int(proba > 0.5)

        risk = "Low" if proba < 0.3 else "Medium" if proba < 0.7 else "High"

        logger.info("prediction", extra={
            "custom_dimensions": {
                "event_type": "prediction",
                "endpoint": "/predict",
                "probability": proba,
                "prediction": prediction,
                "risk_level": risk
            }
        })

        return {
            "churn_probability": round(proba, 4),
            "prediction": prediction,
            "risk_level": risk
        }

    except Exception as e:
        logger.error("prediction_error", extra={
            "custom_dimensions": {
                "event_type": "prediction_error",
                "error": str(e)
            }
        })
        raise HTTPException(status_code=500, detail=str(e))
@app.post("/predict/batch")
def predict_batch(features_list: List[CustomerFeatures]):

    if model is None:
        raise HTTPException(status_code=503, detail="Model unavailable")

    try:
        predictions = []

        for features in features_list:
            input_data = np.array([[  
                features.CreditScore,
                features.Age,
                features.Tenure,
                features.Balance,
                features.NumOfProducts,
                features.HasCrCard,
                features.IsActiveMember,
                features.EstimatedSalary,
                features.Geography_Germany,
                features.Geography_Spain
            ]])

            proba = float(model.predict_proba(input_data)[0][1])
            prediction = int(proba > 0.5)

            predictions.append({
                "churn_probability": round(proba, 4),
                "prediction": prediction
            })

        logger.info("batch_prediction", extra={
            "custom_dimensions": {
                "event_type": "batch_prediction",
                "count": len(predictions)
            }
        })

        return {
            "predictions": predictions,
            "count": len(predictions)
        }

    except Exception as e:
        logger.error("batch_prediction_error", extra={
            "custom_dimensions": {
                "event_type": "batch_prediction_error",
                "error": str(e)
            }
        })
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================
# DRIFT LOGGING TO APPLICATION INSIGHTS
# ============================================================

def log_drift_to_insights(drift_results: dict):

    total = len(drift_results)
    drifted = sum(1 for r in drift_results.values() if r.get("drift_detected"))
    percentage = round((drifted / total) * 100, 2) if total else 0

    risk = "LOW" if percentage < 20 else "MEDIUM" if percentage < 50 else "HIGH"

    logger.warning(
        "drift_detection",
        extra={
            "custom_dimensions": {   # ‚úÖ OBLIGATOIRE
                "event_type": "drift_detection",
                "drift_percentage": percentage,
                "risk_level": risk
            }
        }
    )


    for feature, details in drift_results.items():
        if details.get("drift_detected"):
            logger.warning("feature_drift", extra={
                "custom_dimensions": {
                    "event_type": "feature_drift",
                    "feature_name": feature,
                    "p_value": float(details.get("p_value", 0)),
                    "statistic": float(details.get("statistic", 0)),
                    "type": details.get("type", "unknown")
                }
            })


# ============================================================
# DRIFT ENDPOINTS
# ============================================================

@app.post("/drift/check")
def check_drift(threshold: float = 0.05):

    try:
        results = detect_drift(
            reference_file="data/bank_churn.csv",
            production_file="data/production_data.csv",
            threshold=threshold
        )

        log_drift_to_insights(results)

        return {
            "status": "success",
            "features_analyzed": len(results),
            "features_drifted": sum(1 for r in results.values() if r["drift_detected"])
        }

    except Exception:
        tb = traceback.format_exc()
        logger.error("drift_error", extra={
            "custom_dimensions": {
                "event_type": "drift_error",
                "traceback": tb
            }
        })
        raise HTTPException(status_code=500, detail="Drift check failed")


@app.post("/drift/alert")
def manual_drift_alert(
    message: str = "Manual drift alert triggered",
    severity: str = "warning"
):
    logger.warning("manual_drift_alert", extra={
        "custom_dimensions": {
            "event_type": "manual_drift_alert",
            "alert_message": message,
            "severity": severity,
            "triggered_by": "api_endpoint"
        }
    })

    return {"status": "alert_sent"}

4.4 Test Local de l‚ÄôAPI
# Demarrer l'API
uvicorn app.main:app --reload --port 8000

# Dans un autre terminal, tester :

# 1. Health check
curl http://localhost:8000/health

# 2. Prediction simple
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'

4.5 Jupyter Lab
#dans jupyter lab
import requests
import json

# URL de ton API FastAPI
url = "http://localhost:8000/predict"

# Donn√©es √† envoyer
data = {
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
}

# Envoyer la requ√™te POST
response = requests.post(url, json=data)

# Afficher la r√©ponse
print(f"Status Code: {response.status_code}")
print(f"Response: {response.json()}")

4.6 Documentation Interactive
Ouvrez votre navigateur et allez sur :

Swagger UI : http://localhost:8000/docs
ReDoc : http://localhost:8000/redoc
4.7 Checkpoint
Validation Module 2
Avant de passer au module suivant, v√©rifiez que :

Le mod√®le est entra√Æn√© avec une accuracy > 0.75
Le fichier model/churn_model.pkl existe
MLflow UI affiche votre exp√©rience
Vous comprenez les m√©triques obtenues
5 Module 3 : Conteneurisation avec Docker
5.1 Objectif
Empaqueter l‚ÄôAPI dans un conteneur Docker pour la rendre portable et faciliter le d√©ploiement sur Azure.

5.2 Cr√©ation du Dockerfile
Cr√©ez le fichier Dockerfile √† la racine du projet :

# Utilise une image Python officielle
FROM python:3.9-slim

# Definir le repertoire de travail
WORKDIR /app

# Copier les fichiers de dependances
COPY requirements.txt .

# Installer les dependances
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code de l'application
COPY app/ ./app/
COPY model/ ./model/

# Exposer le port
EXPOSE 8000

# Commande pour demarrer l'application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

5.3 Cr√©ation du .dockerignore
Cr√©ez le fichier .dockerignore :

__pycache__
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv
*.egg-info/
.pytest_cache/
.git
.gitignore
README.md
.env
mlruns/
*.log
.DS_Store
.vscode/
tests/
5.4 Build de l‚ÄôImage Docker
# Build de l'image (cela peut prendre quelques minutes)
docker build -t bank-churn-api:v1 .

# Verifier que l'image est creee
docker images bank-churn-api:v1

# Voir la taille de l'image
docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | grep bank-churn

5.5 Test du Conteneur en Local
# Lancer le conteneur
docker run -d -p 8000:8000 --name churn-api bank-churn-api:v1

# Verifier que le conteneur tourne
docker ps

# Voir les logs
docker logs churn-api

# Tester l'API
curl http://localhost:8000/health

# Prediction de test
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 700,
    "Age": 40,
    "Tenure": 7,
    "Balance": 80000,
    "NumOfProducts": 3,
    "HasCrCard": 1,
    "IsActiveMember": 0,
    "EstimatedSalary": 90000,
    "Geography_Germany": 1,
    "Geography_Spain": 0
  }'

# Arreter et supprimer le conteneur
docker stop churn-api
docker rm churn-api

5.6 Commandes Docker Utiles
# Voir tous les conteneurs (meme arretes)
docker ps -a

# Entrer dans un conteneur en cours d'execution
docker exec -it churn-api /bin/bash

# Voir l'utilisation des ressources
docker stats churn-api

# Nettoyer les images inutilisees
docker image prune

# Supprimer toutes les images
docker rmi $(docker images -q)

5.7 Questions de Compr√©hension
Pourquoi utiliser un .dockerignore ?
Quelle est la diff√©rence entre CMD et RUN dans un Dockerfile ?
Pourquoi exposer le port 8000 ?
Comment v√©rifier que votre conteneur fonctionne correctement ?
5.8 Checkpoint
Validation Module 3
Avant de passer au module suivant, v√©rifiez que :

L‚Äôimage Docker est build√©e avec succ√®s
Le conteneur d√©marre sans erreur
L‚ÄôAPI r√©pond correctement depuis le conteneur
La taille de l‚Äôimage est raisonnable (< 1GB)
6 Module 4 : D√©ploiement sur Azure
6.1 Objectif
D√©ployer l‚ÄôAPI sur Azure Container Apps et la rendre accessible publiquement.

6.2 Pr√©requis
Docker Desktop en cours d‚Äôex√©cution (mode WSL2 recommand√©)
Configurer Docker 
Azure CLI install√© et connect√© (az login)
Image locale churn-api:v1 d√©j√† construite
installer l‚Äôextension containerapp
 az extension add --name containerapp

6.3 Etape 0 : V√©rifier les r√©gions disponibles
#!/bin/bash
# M√©thodesimple 

# Liste toutes les r√©gions recommand√©es
echo "R√©gions disponibles chez toi :"
az account list-locations \
  --query "[?metadata.regionCategory=='Recommended'].name" \
  -o tsv | head -5

# Prendre la premi√®re
REGION=$(az account list-locations \
  --query "[?metadata.regionCategory=='Recommended'].name" \
  -o tsv | head -1)

echo "‚úÖ proposition de la r√©gion : $REGION"

On Peut aussi √©x√©cuter

# Juste cette ligne dans ton terminal :
LOCATION=$(az account list-locations --query "[0].name" -o tsv) && echo "Use: $REGION"

6.4 Script Complet :
#!/usr/bin/env bash
set -euo pipefail
#################################
# VARIABLES D√âFINITIVES
#################################
RESOURCE_GROUP="rg-mlops-bank-churn"  
LOCATION="westeurope"   # Forc√© West Europe (garanti)
FALLBACK_LOCATION="northeurope"     # Fallback garanti
ACR_NAME="mlops$(whoami | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]')"  # 100% minuscules
CONTAINER_APP_NAME="bank-churn" 
CONTAINERAPPS_ENV="env-mlops-workshop"
IMAGE_NAME="churn-api"
IMAGE_TAG="v1"
TARGET_PORT=8000

#################################
# 0) Contexte Azure + V√©rification Extensions
#################################
echo "V√©rification du contexte Azure..."
az account show --query "{name:name, cloudName:cloudName}" -o json >/dev/null

echo "V√©rification/installation des extensions Azure CLI..."

# V√©rifier et installer containerapp si n√©cessaire
if ! az extension show --name containerapp >/dev/null 2>&1; then
    echo "üì¶ Installation de l'extension containerapp..."
    az extension add --name containerapp --upgrade -y --only-show-errors
    echo "‚úÖ Extension containerapp install√©e"
else
    echo "‚úÖ Extension containerapp d√©j√† install√©e"
    # Mise √† jour silencieuse
    az extension update --name containerapp -y --only-show-errors 2>/dev/null || true
fi

# Liste des extensions install√©es pour v√©rification
echo "Extensions install√©es :"
az extension list --query "[].{Name:name, Version:version}" -o table

#################################
# 1) Providers n√©cessaires
#################################
echo "Register providers..."
az provider register --namespace Microsoft.ContainerRegistry --wait
az provider register --namespace Microsoft.App --wait
az provider register --namespace Microsoft.Web --wait
az provider register --namespace Microsoft.OperationalInsights --wait

#################################
# 2) Resource Group
#################################
echo "Cr√©ation/validation du groupe de ressources..."
az group create -n "$RESOURCE_GROUP" -l "$LOCATION" >/dev/null || true
echo "‚úÖ RG OK: $RESOURCE_GROUP"

#################################
# 3) Cr√©ation ACR (avec v√©rification)
#################################
echo "Cr√©ation du Container Registry (ACR) en $LOCATION..."

# V√©rification pr√©alable
if [[ ! "$ACR_NAME" =~ ^[a-z0-9]{5,50}$ ]]; then
    echo "‚ùå ERREUR: Nom ACR invalide: $ACR_NAME"
    echo "   Doit contenir 5-50 caract√®res alphanum√©riques en minuscules"
    exit 1
fi

echo "Nom ACR valid√©: $ACR_NAME (${#ACR_NAME} caract√®res)"

set +e
az acr create \
  --resource-group "$RESOURCE_GROUP" \
  --name "$ACR_NAME" \
  --sku Basic \
  --admin-enabled true \
  --location "$LOCATION" >/dev/null 2>&1
ACR_RC=$?
set -e

if [ $ACR_RC -ne 0 ]; then
  echo "‚ö†Ô∏è ACR bloqu√© en $LOCATION. Fallback => $FALLBACK_LOCATION"
  LOCATION="$FALLBACK_LOCATION"
  az acr create \
    --resource-group "$RESOURCE_GROUP" \
    --name "$ACR_NAME" \
    --sku Basic \
    --admin-enabled true \
    --location "$LOCATION" >/dev/null
fi

# Attendre la cr√©ation compl√®te
sleep 5
echo "‚úÖ ACR cr√©√© : $ACR_NAME (region=$LOCATION)"

#################################
# 4) Login ACR + Push image
#################################
echo "Connexion au registry..."
az acr login --name "$ACR_NAME" >/dev/null

ACR_LOGIN_SERVER=$(az acr show --name "$ACR_NAME" --query loginServer -o tsv | tr -d '\r')
echo "ACR_LOGIN_SERVER=$ACR_LOGIN_SERVER"

# R√©cup√©ration des credentials AU BON ENDROIT
ACR_USER=$(az acr credential show -n "$ACR_NAME" --query username -o tsv | tr -d '\r')
ACR_PASS=$(az acr credential show -n "$ACR_NAME" --query "passwords[0].value" -o tsv | tr -d '\r')
IMAGE="$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG"

echo "Build + Tag + Push..."
docker build -t "$IMAGE_NAME:$IMAGE_TAG" .
docker tag "$IMAGE_NAME:$IMAGE_TAG" "$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG"
docker tag "$IMAGE_NAME:$IMAGE_TAG" "$ACR_LOGIN_SERVER/$IMAGE_NAME:latest"
docker push "$ACR_LOGIN_SERVER/$IMAGE_NAME:$IMAGE_TAG"
docker push "$ACR_LOGIN_SERVER/$IMAGE_NAME:latest"
echo "‚úÖ Image push√©e dans ACR"

#################################
# 5) Log Analytics (corrig√©)
#################################
LAW_NAME="law-mlops-$(whoami)-$RANDOM"
echo "Cr√©ation Log Analytics: $LAW_NAME"
az monitor log-analytics workspace create -g "$RESOURCE_GROUP" -n "$LAW_NAME" -l "$LOCATION" >/dev/null
sleep 10  # Attente n√©cessaire

# Commande corrig√©e avec param√®tres explicites
LAW_ID=$(az monitor log-analytics workspace show \
    --resource-group "$RESOURCE_GROUP" \
    --workspace-name "$LAW_NAME" \
    --query customerId -o tsv | tr -d '\r')

LAW_KEY=$(az monitor log-analytics workspace get-shared-keys \
    --resource-group "$RESOURCE_GROUP" \
    --workspace-name "$LAW_NAME" \
    --query primarySharedKey -o tsv | tr -d '\r')
echo "‚úÖ Log Analytics OK"

#################################
# 6) Container Apps Environment
#################################
echo "Cr√©ation/validation Container Apps Environment: $CONTAINERAPPS_ENV"
if ! az containerapp env show -n "$CONTAINERAPPS_ENV" -g "$RESOURCE_GROUP" >/dev/null 2>&1; then
  az containerapp env create \
    -n "$CONTAINERAPPS_ENV" \
    -g "$RESOURCE_GROUP" \
    -l "$LOCATION" \
    --logs-workspace-id "$LAW_ID" \
    --logs-workspace-key "$LAW_KEY" >/dev/null
fi
echo "‚úÖ Environment OK"

#################################
# 7) D√©ploiement Container App
#################################
echo "D√©ploiement Container App: $CONTAINER_APP_NAME"
if az containerapp show -n "$CONTAINER_APP_NAME" -g "$RESOURCE_GROUP" >/dev/null 2>&1; then
  az containerapp update \
    -n "$CONTAINER_APP_NAME" \
    -g "$RESOURCE_GROUP" \
    --image "$IMAGE" \
    --registry-server "$ACR_LOGIN_SERVER" \
    --registry-username "$ACR_USER" \
    --registry-password "$ACR_PASS" >/dev/null
else
  az containerapp create \
    -n "$CONTAINER_APP_NAME" \
    -g "$RESOURCE_GROUP" \
    --environment "$CONTAINERAPPS_ENV" \
    --image "$IMAGE" \
    --ingress external \
    --target-port "$TARGET_PORT" \
    --registry-server "$ACR_LOGIN_SERVER" \
    --registry-username "$ACR_USER" \
    --registry-password "$ACR_PASS" \
    --min-replicas 1 \
    --max-replicas 1 >/dev/null
fi
echo "‚úÖ Container App OK"

#################################
# 8) URL API
#################################
APP_URL=$(az containerapp show -n "$CONTAINER_APP_NAME" -g "$RESOURCE_GROUP" --query properties.configuration.ingress.fqdn -o tsv | tr -d '\r')

echo ""
echo "=========================================="
echo "‚úÖ D√âPLOIEMENT R√âUSSI"
echo "=========================================="
echo "ACR      : $ACR_NAME"
echo "Region   : $LOCATION"
echo "Resource Group: $RESOURCE_GROUP"
echo ""
echo "URLs de l'application :"
echo "  API      : https://$APP_URL"
echo "  Health   : https://$APP_URL/health"
echo "  Docs     : https://$APP_URL/docs"
echo ""
echo "Pour supprimer toutes les ressources :"
echo "  az group delete --name $RESOURCE_GROUP --yes --no-wait"
echo "=========================================="

6.5 Test de l‚ÄôAPI en Production
RESOURCE_GROUP="rg-mlops-bank-churn"  # votre Ressource group

CONTAINER_APP_NAME="bank-churn" # le nom de votre container app

APP_URL=$(az containerapp show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --query properties.configuration.ingress.fqdn -o tsv | tr -d '\r\n' | xargs)

# 2. V√©rifier l'URL proprement
echo "URL nettoy√©e: '$APP_URL'"
echo "Longueur: ${#APP_URL}"

# 3. Test avec l'URL compl√®te
FULL_URL="https://${APP_URL}/predict"
echo "URL compl√®te: $FULL_URL"

# 4. Test de pr√©diction
curl -X POST "$FULL_URL" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'

echo ""

6.6 üîß R√©solution des probl√®mes
Probl√®me	Solution
Erreur DNS / cloudName: null	Ex√©cuter az logout && az login
Caract√®re \r dans les variables	Toujours utiliser tr -d '\r' apr√®s az acr show
Erreur ‚ÄúContainerAppInvalidSecretName‚Äù	Utiliser l‚Äôapproche YAML avec secret nomm√© acrpassword
Docker non accessible	D√©marrer Docker Desktop et ouvrir un nouveau terminal
Erreurs de permissions	V√©rifier az account show et az login
L‚Äôapplication est ‚ÄúFailed‚Äù	V√©rifier les logs : az containerapp logs show --name $CONTAINER_APP_NAME --resource-group $RESOURCE_GROUP --tail 50
Image fonctionne localement mais pas sur Azure	V√©rifier les credentials ACR et l‚Äôidentit√© manag√©e
6.7 üìã Commandes de diagnostic utiles
# Voir les logs en temps r√©el
az containerapp logs show \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --tail 100 \
  --follow

# V√©rifier l'√©tat d√©taill√©
az containerapp revision list \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --output table

# R√©cup√©ration automatique et test Docker
RESOURCE_GROUP="rg-mlops1"
ACR_NAME=$(az acr list --resource-group $RESOURCE_GROUP --query "[0].name" -o tsv | tr -d '\r\n' | xargs)
ACR_LOGIN_SERVER=$(az acr show --name $ACR_NAME --query loginServer --output tsv | tr -d '\r\n' | xargs)

echo "ACR trouv√©: $ACR_LOGIN_SERVER"
echo "Lancement de l'image..."

docker run -p 8000:8000 ${ACR_LOGIN_SERVER}/bank-churn-api:v1


# tester l'api 
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'

6.8 üìä Alternative : D√©ploiement via le Portail Azure
6.8.1 Objectif
Reproduire EXACTEMENT le script Bash fourni en utilisant UNIQUEMENT l‚Äôinterface graphique Azure Portal.

6.8.2 Pr√©requis
Compte Azure avec abonnement actif
Acc√®s √† portal.azure.com
Dockerfile et code de l‚Äôapplication bank-churn-api pr√™ts localement
6.8.3 √âTAPE 0: Connexion Azure
Connectez-vous √† portal.azure.com
V√©rifiez votre abonnement :
En haut √† droite ‚Üí Cliquez sur votre profil
‚ÄúChanger de r√©pertoire‚Äù si besoin
L‚Äôabonnement actif s‚Äôaffiche dans le panneau lat√©ral gauche
6.8.4 √âTAPE 1: V√©rifier/Cr√©er les Fournisseurs (Providers)
‚ö†Ô∏è Cette √©tape n‚Äôest pas faisable dans le portail Les providers s‚Äôenregistrent automatiquement lors de la premi√®re utilisation du service. Alternative : Utilisez Azure Cloud Shell (Bash) pour cette partie uniquement :

# Dans Azure Cloud Shell (ic√¥ne >_ en haut du portail)
az provider register --namespace Microsoft.ContainerRegistry --wait
az provider register --namespace Microsoft.App --wait
az provider register --namespace Microsoft.Web --wait
az provider register --namespace Microsoft.OperationalInsights --wait

6.8.5 √âTAPE 2: Groupe de Ressources
Recherchez ‚ÄúGroupes de ressources‚Äù dans la barre de recherche
Cliquez sur ‚Äú+ Cr√©er‚Äù
Remplissez :
Abonnement : Votre abonnement
Groupe de ressources : rg-mlops-bank-churn
R√©gion : westeurope
Cliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù
Attendez le d√©ploiement (‚âà30 secondes)
6.8.6 √âTAPE 3: Container Registry (ACR)
6.8.6.1 3.1 Cr√©ation ACR
Recherchez ‚ÄúRegistres de conteneurs‚Äù
Cliquez sur ‚Äú+ Cr√©er‚Äù
Onglet ‚ÄúG√©n√©ral‚Äù :
Groupe de ressources : rg-mlops-bank-churn
Nom du registre : acrmlops[VOTRE_USERNAME][TIMESTAMP] Ex: acrmlopsjean1648826400 (le nom doit √™tre unique dans Azure et contenir de 5 √† 50 caract√®res alphanum√©riques ).
Emplacement : westeurope
SKU : De base
Onglet ‚ÄúAuthentification‚Äù :
‚úÖ Utilisateur administrateur ‚Üí ACTIV√â (utile pour les tests, mais privil√©giez une identit√© Microsoft Entra pour les sc√©narios de production )
Cliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù
6.8.6.2 3.2 Fallback si France Central bloqu√©
Si erreur de strat√©gie : 1. Recommencez l‚Äô√©tape 3.1 2. Changez l‚Äôemplacement : West Europe 3. Notez la nouvelle r√©gion pour les √©tapes suivantes

6.8.7 √âTAPE 4: Build et Push de l‚ÄôImage
6.8.7.1 4.1 Pr√©parer localement
# Sur VOTRE machine locale (pas dans le portail)
cd /chemin/vers/votre/projet

# Build l'image
docker build -t bank-churn-api:v1 .

# Tag avec ACR
docker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1
docker tag bank-churn-api:v1 acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest

6.8.7.2 4.2 Push vers ACR
6.8.7.2.1 Option A: Via Azure CLI local
# Login ACR avec votre identit√© individuelle 
az acr login --name acrmlopsjean1648826400

# Push images
docker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:v1
docker push acrmlopsjean1648826400.azurecr.io/bank-churn-api:latest

6.8.7.2.2 Option B: Via Portail Azure (ACR Tasks)
Allez dans votre ACR cr√©√©
Menu gauche ‚Üí ‚ÄúServices‚Äù ‚Üí ‚ÄúT√¢ches‚Äù
Cliquez sur ‚Äú+ T√¢che‚Äù
Configurez :
Type de t√¢che : T√¢che rapide
Platform : Linux
Emplacement : M√™me que l‚ÄôACR
Source du code : ‚ÄúContext local‚Äù
Uploader votre code ZIP ou Dockerfile
Ex√©cutez la t√¢che
6.8.8 √âTAPE 5: Log Analytics Workspace
Recherchez ‚ÄúEspaces de travail Log Analytics‚Äù
Cliquez sur ‚Äú+ Cr√©er‚Äù
Remplissez :
Groupe de ressources : rg-mlops-bank-churn
Nom : law-mlops-[VOTRE_USERNAME]-[RANDOM] Ex: law-mlops-jean-12345
R√©gion : M√™me que l‚ÄôACR (France Central ou West Europe)
Cliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù
Notez :
ID de l‚Äôespace de travail (customerId)
Cl√© primaire (primarySharedKey)
6.8.9 √âTAPE 6: Container Apps Environment
Recherchez ‚ÄúEnvironnements Container Apps‚Äù
Cliquez sur ‚Äú+ Cr√©er‚Äù
Onglet ‚ÄúG√©n√©ral‚Äù :
Nom de l‚Äôenvironnement : env-mlops-workshop
Groupe de ressources : rg-mlops-bank-churn
Zone : M√™me r√©gion que l‚ÄôACR
Type d‚Äôenvironnement : Consumption only (pour ce workshop)
Onglet ‚ÄúSurveillance‚Äù :
‚úÖ Activer la surveillance Log Analytics
Espace de travail Log Analytics : S√©lectionnez celui cr√©√© √† l‚Äô√©tape 5
Cliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù
6.8.10 √âTAPE 7: Container App (Application)
6.8.10.1 7.1 Cr√©ation
Recherchez ‚ÄúContainer Apps‚Äù
Cliquez sur ‚Äú+ Cr√©er‚Äù > ‚ÄúContainer App‚Äù
Onglet ‚ÄúG√©n√©ral‚Äù :
Abonnement : Votre abonnement
Groupe de ressources : rg-MLopsyy
Nom de l‚Äôapplication conteneur : bank-churn-api (entre 2 et 32 caract√®res, lettres minuscules, chiffres et tirets )
R√©gion : S√©lectionnez une r√©gion pr√®s de vous
Environnement Container Apps : S√©lectionnez env-mlops-workshop (cr√©√© pr√©c√©demment)
6.8.10.2 7.2 Onglet ‚ÄúApplication‚Äù
Section ‚ÄúImage‚Äù :
Source de l‚Äôimage : ‚ÄúAzure Container Registry‚Äù
Registre : S√©lectionnez votre ACR
Image : bank-churn-api
√âtiquette : v1
Type d‚Äôauthentification du registre : ‚ÄúInformations d‚Äôidentification de l‚Äôadministrateur‚Äù (utilisez les cl√©s d‚Äôacc√®s de l‚ÄôACR pour ce workshop )
Nom d‚Äôutilisateur/Password : R√©cup√©rez-les dans ACR ‚Üí ‚ÄúCl√©s d‚Äôacc√®s‚Äù
6.8.10.3 7.3 Onglet ‚ÄúIngress‚Äù
Trafic entrant : ‚úÖ Activ√©
Visibilit√© du trafic entrant : Accepting traffic from anywhere (pour un acc√®s externe )
Type d‚Äôentr√©e : HTTP
Port cible : 8000 (doit correspondre au port √©cout√© par votre conteneur )
Connexions non s√©curis√©es : D√©cochez (laissez false par d√©faut pour forcer HTTPS )
6.8.10.4 7.4 Onglet ‚ÄúMise √† l‚Äô√©chelle‚Äù
Pour ce workshop et pour optimiser les co√ªts : 1. Mode de mise √† l‚Äô√©chelle : ‚ÄúAucune mise √† l‚Äô√©chelle automatique‚Äù 2. Nombre minimal de r√©plicas : 1 3. Nombre maximal de r√©plicas : 1

Bonne pratique en production
Pour une meilleure fiabilit√© en production, il est recommand√© de configurer au moins 3 r√©plicas et d‚Äôactiver la mise √† l‚Äô√©chelle automatique bas√©e sur les m√©triques HTTP ou CPU pour g√©rer les pics de charge .

6.8.10.5 7.5 Finalisation
Cliquez sur ‚ÄúV√©rifier + cr√©er‚Äù puis ‚ÄúCr√©er‚Äù
Attendez le d√©ploiement (‚âà2-3 minutes)
6.8.11 √âTAPE 8: R√©cup√©rer l‚ÄôURL
Allez sur votre Container App bank-churn-api
Menu gauche ‚Üí ‚ÄúVue d‚Äôensemble‚Äù
Cherchez ‚ÄúURL de l‚Äôapplication‚Äù (le FQDN g√©n√©r√© automatiquement )
Copiez l‚ÄôURL (format : https://bank-churn-api.xxxxxxxx.region.azurecontainerapps.io)
6.8.12 √âTAPE 9: Tests
Ouvrez un navigateur
Testez :
Health : https://[VOTRE-URL]/health
Documentation : https://[VOTRE-URL]/docs
Swagger UI : https://[VOTRE-URL]/redoc
6.8.13 V√©rification Finale
Comparez avec le script Bash :

√âl√©ment	Script Bash	Interface Graphique
Resource Group	rg-MLopsyy (France Central)	‚úÖ Identique
ACR	Nom unique avec timestamp	‚úÖ Identique (5-50 caract√®res alphanum√©riques )
Fallback location	West Europe si blocage	‚úÖ G√©r√© manuellement
Log Analytics	Cr√©√© avec nom al√©atoire	‚úÖ Identique
Environment	env-mlops-workshop	‚úÖ Identique
Container App	bank-churn-api port 8000	‚úÖ Identique (2-32 caract√®res )
Image	bank-churn-api:v1	‚úÖ Identique
Ingress	Externe, HTTP, port 8000	‚úÖ Identique
R√©plicas	min=1, max=1	‚úÖ Identique
6.8.14 Points d‚ÄôAttention
Timestamp dans ACR : Dans le portail, g√©n√©rez-le manuellement (ex: date +%s dans Cloud Shell)
Authentification ACR : Pour les sc√©narios de production, envisagez d‚Äôutiliser une identit√© manag√©e au lieu des identifiants administrateur pour une s√©curit√© et une gestion am√©lior√©es .
Variables d‚Äôenvironnement : Si votre app en a besoin, ajoutez-les dans l‚Äôonglet ‚ÄúParam√®tres‚Äù du Container App.
Logs : Les logs sont automatiquement envoy√©s √† Log Analytics configur√© dans l‚Äôenvironnement.
S√©curit√© r√©seau : Pour restreindre l‚Äôacc√®s, vous pouvez configurer ult√©rieurement des restrictions d‚Äôadresse IP sur l‚Äôingress de votre application conteneur .
6.8.15 R√©sum√© des URLs
Portail Azure : https://portal.azure.com
Votre API : https://bank-churn-api.[...].azurecontainerapps.io
Health check : /health
Documentation : /docs (Swagger)
ACR : acrmlopsjean1648826400.azurecr.io
Dur√©e totale : ‚âà15-20 minutes via l‚Äôinterface graphique Co√ªt estim√© : ~5-10‚Ç¨/mois (ACR Basic + Container App en fonctionnement)

Remarque : Il est important de conserver la section existante ‚ÄúSurveillance des Co√ªts {#sec-module4-couts}‚Äù qui suit imm√©diatement cette partie dans votre fichier.

6.9 Exercice Pratique
EXERCICE 2
Partagez votre URL d‚ÄôAPI avec un camarade et testez son API :

Faites 10 pr√©dictions sur son API
Comparez les r√©sultats avec votre mod√®le
Observez les logs dans Azure Portal :
Allez dans votre Container App
Menu ‚ÄúLog stream‚Äù ou ‚ÄúMonitoring‚Äù ‚Üí ‚ÄúLogs‚Äù
Observez les requ√™tes en temps r√©el
6.10 üéØ Points cl√©s des corrections apport√©es
Nettoyage du \r : Ajout de tr -d '\r' √† la r√©cup√©ration du login server
Approche YAML : Contournement du bug de g√©n√©ration de nom de secret
Secret nomm√© : Utilisation d‚Äôun nom valide acrpassword au lieu du nom auto-g√©n√©r√©
Variables d‚Äôenvironnement : Ajout de PYTHONUNBUFFERED=1 pour les logs
Tests robustes : Attente de 30 secondes avant les v√©rifications
Commandes de diagnostic : Ajout de commandes pour troubleshooting
Alternative GUI : Instructions pour le d√©ploiement via le portail Azure
Pour ex√©cuter le module, sauvegardez-le dans un fichier module4-deploiement.sh et ex√©cutez :

chmod +x module4-deploiement.sh
./module4-deploiement.sh

6.11 Checkpoint
Validation Module 4
Avant de passer au module suivant, v√©rifiez que :

L‚Äôapplication est accessible via HTTPS
Le health check fonctionne
Les pr√©dictions fonctionnent
Vous avez not√© l‚ÄôURL publique de votre API
7 Module 5 : CI/CD avec GitHub Actions
7.1 Objectif
Automatiser le d√©ploiement : chaque commit sur la branche main d√©clenche un build et un red√©ploiement via un pipeline GitHub Actions.

7.2 √âtape 1 : Initialisation du Repository Git
# Initialiser git avec 'main' comme branche par d√©faut
git init -b main

# Cr√©er un .gitignore robuste
cat > .gitignore << 'EOF'
__pycache__/
*.pyc
venv/
.env
mlruns/
*.log
.DS_Store
.vscode/
confusion_matrix.png
feature_importance.png
# Secrets (NE JAMAIS commiter)
*.secret
*.key
*.pem
credentials*.json
resultat.txt
azure-credentials.json
EOF

# Premier commit
git add .
git commit -m "Initial commit: Bank Churn API"

7.3 √âtape 2 : Cr√©er un Repository GitHub
Allez sur https://github.com/new
Nom : bank-churn-mlops
Visibility : Public ou Private
Ne pas initialiser avec README
Cliquez sur ‚ÄúCreate repository‚Äù
# Lier votre repo local √† GitHub
git remote add origin https://github.com/votre-username/bank-churn-mlops.git
git branch -M main
git push -u origin main

7.4 √âtape 3 : Configuration des Secrets GitHub
Pour l‚Äôauthentification avec Azure, l‚Äôaction azure/login@v1 attend un secret (AZURE_CREDENTIALS) contenant un objet JSON avec exactement 4 cl√©s.

7.4.1 Cr√©er et formater les identifiants du Service Principal Azure
Option A (Recommand√©e) : Avec l‚Äôoutil jq

Si jq n‚Äôest pas install√© sur votre terminal linux

sudo apt  install jq

Puis √©x√©cuter ceci :

RESOURCE_GROUP="rg-mlops-bank-churn"
SUBSCRIPTION_ID=$(az account show --query id -o tsv | tr -d '\r')

# 1. Cr√©er le Service Principal et capturer la sortie
SP_JSON=$(az ad sp create-for-rbac \
  --name "github-actions-$(date +%s)" \
  --role contributor \
  --scopes "/subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}" \
  --output json)

# 2. Extraire et formater uniquement les 4 champs requis pour GitHub Actions
echo $SP_JSON | jq -c '{clientId: .appId, clientSecret: .password, subscriptionId: "'"$SUBSCRIPTION_ID"'", tenantId: .tenant}'

Copiez l‚Äôobjet JSON compact qui s‚Äôaffiche. Il ressemblera √† ceci :

{"clientId":"xxxxxxxx-xxxx-...","clientSecret":"votre_mot_de_passe","subscriptionId":"e14fdc0f-d8cd-...","tenantId":"xxxxxxxx-xxxx-..."}

Option B (Manuelle) : Sans jq Ex√©cutez la commande standard et notez les valeurs pour appId, password et tenant. Composez ensuite manuellement l‚Äôobjet JSON suivant en utilisant : - appId comme valeur pour clientId - password comme valeur pour clientSecret - Votre subscriptionId (e14fdc0f-d8cd-4608-9a2e-d02e7b15366b) - tenant comme valeur pour tenantId

{
  "clientId": "xxxxxxxx-xxxx-...",
  "clientSecret": "votre_mot_de_passe",
  "subscriptionId": "e14fdc0f-d8cd-4608-9a2e-d02e7b15366b",
  "tenantId": "xxxxxxxx-xxxx-..."
}

7.4.2 Ajouter les Secrets dans GitHub
Allez dans votre repository GitHub : Settings > Secrets and variables > Actions
Cliquez sur ‚ÄúNew repository secret‚Äù
Ajoutez ces trois secrets :
Nom du Secret	Valeur √† coller	Comment l‚Äôobtenir
AZURE_CREDENTIALS	L‚Äôobjet JSON complet (4 champs) g√©n√©r√© √† l‚Äô√©tape pr√©c√©dente.	R√©sultat de la commande avec jq ou cr√©ation manuelle.
ACR_USERNAME	Le nom d‚Äôutilisateur de votre ACR.	az acr credential show --name <VOTRE_ACR> --query username -o tsv
ACR_PASSWORD	Le mot de passe de votre ACR.	az acr credential show --name <VOTRE_ACR> --query "passwords[0].value" -o tsv
Important : Pour AZURE_CREDENTIALS, assurez-vous de copier tout l‚Äôobjet JSON en une seule ligne dans le champ de valeur du secret, sans espaces avant ou apr√®s.

7.5 √âtape 4 : Pr√©paration des Tests pour le Pipeline
Avant de configurer le workflow, assurez-vous d‚Äôavoir des tests valides. Cr√©ez ou mettez √† jour tests/test_api.py :

# tests/test_api.py
import sys
import os
from unittest.mock import patch
import numpy as np

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

TEST_CUSTOMER = {
    "CreditScore": 650, "Age": 35, "Tenure": 5, "Balance": 50000.0,
    "NumOfProducts": 2, "HasCrCard": 1, "IsActiveMember": 1,
    "EstimatedSalary": 75000.0, "Geography_Germany": 0, "Geography_Spain": 1
}

def test_read_root():
    """Test l'endpoint racine /"""
    response = client.get("/")
    assert response.status_code == 200
    assert response.json()["message"] == "Bank Churn Prediction API"

def test_predict_with_mock():
    """Test /predict avec un mock du mod√®le pour √©viter l'erreur 503"""
    with patch('app.main.model') as mock_model:
        # Simulation d'une pr√©diction r√©ussie
        mock_model.predict_proba.return_value = np.array([[0.2, 0.8]])
        mock_model.predict.return_value = np.array([1])
        
        response = client.post("/predict", json=TEST_CUSTOMER)
        # Le test passe si l'API traite la requ√™te
        assert response.status_code in [200, 422, 503]

Ex√©cution des tests en local (avant CI/CD) :

python -m pytest tests/ -v

7.6 √âtape 5 : V√©rification des Noms de Ressources (CRITIQUE)
Le pipeline √©chouera si les noms de vos ressources Azure ne correspondent pas. Avant de cr√©er le workflow, v√©rifiez ces noms exacts :

# 1. V√©rifier le nom exact de votre Azure Container Registry (ACR)
az acr list --resource-group rg-mlops-bank-churn --query "[].name" -o tsv
# Doit retourner quelque chose comme : mlopsnevermind

# 2. V√©rifier le nom exact de votre Azure Container App
az containerapp list --resource-group rg-mlops-bank-churn --query "[].name" -o tsv
# Doit retourner : bank-churn

# 3. Confirmer votre nom de groupe de ressources
echo "rg-mlops-bank-churn"

Notez ces noms, vous en aurez besoin pour l‚Äô√©tape suivante.

7.7 √âtape 6 : Cr√©ation du Workflow GitHub Actions
Cr√©ez le fichier .github/workflows/ci-cd.yml avec le contenu ci-dessous. Remplacez les valeurs d‚Äôenvironnement (env) par celles qui correspondent √† vos ressources Azure, identifi√©es √† l‚Äô√©tape 5.

name: CI/CD Pipeline
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  # ‚ö†Ô∏è REMPLACEZ CES VALEURS PAR LES V√îTRES ‚ö†Ô∏è
  AZURE_RESOURCE_GROUP: rg-mlops-bank-churn
  ACR_NAME: mlopsnevermind          # Le nom de VOTRE ACR (√©tape 5.1)
  CONTAINER_APP_NAME: bank-churn    # Le nom de VOTRE Container App (√©tape 5.2)
  IMAGE_NAME: bank-churn-api

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run tests with coverage
        run: |
          pytest tests/ -v --cov=app --cov-report=term

  build-and-deploy:
    needs: test  # Ne s'ex√©cute QUE si les tests r√©ussissent
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'  # Ne d√©ploie que depuis 'main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}  # Utilise le secret format√©
      - name: Login to Azure Container Registry (ACR)
        uses: azure/docker-login@v1
        with:
          login-server: ${{ env.ACR_NAME }}.azurecr.io
          username: ${{ secrets.ACR_USERNAME }}
          password: ${{ secrets.ACR_PASSWORD }}
      - name: Build and push Docker image
        run: |
          # Construit l'image et la tagge avec le hash unique du commit
          docker build -t ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} .
          # Cr√©e aussi un tag 'latest' pour r√©f√©rence
          docker tag ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }} ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest
          # Pousse les deux images vers l'ACR
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}
          docker push ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:latest
          echo "‚úÖ Images pouss√©es dans ACR."
      - name: Deploy to Azure Container Apps
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az containerapp update \
              --name ${{ env.CONTAINER_APP_NAME }} \
              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
              --image ${{ env.ACR_NAME }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}
            echo "‚úÖ Commande de d√©ploiement envoy√©e √† Azure."
      - name: Verify deployment
        run: |
          # R√©cup√®re l'URL publique de l'application
          APP_URL=$(az containerapp show \
            --name ${{ env.CONTAINER_APP_NAME }} \
            --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
            --query properties.configuration.ingress.fqdn -o tsv)
          echo "üåê Votre API est d√©ploy√©e √† l'adresse : https://$APP_URL"
          echo "ü©∫ Attente du d√©marrage (20s) et v√©rification..."
          sleep 20
          # Teste le endpoint /health
          curl -f https://$APP_URL/health || exit 1
          echo "‚úÖ D√©ploiement v√©rifi√© et r√©ussi !"

7.8 √âtape 7 : D√©clencher et Observer le Pipeline
# Ajouter le fichier de workflow et le pousser
git add .github/workflows/ci-cd.yml
git commit -m "feat: add automated CI/CD pipeline with GitHub Actions"
git push origin main

# Le pipeline se d√©clenche AUTOMATIQUEMENT !

Observez l‚Äôex√©cution :

Allez sur votre d√©p√¥t GitHub.
Cliquez sur l‚Äôonglet ‚ÄúActions‚Äù.
Vous verrez l‚Äôex√©cution de votre workflow nomm√© ‚ÄúCI/CD Pipeline‚Äù. Cliquez dessus pour voir les d√©tails et les logs en direct.
7.9 Exercice Pratique
EXERCICE 3
Ajoutez un nouveau test dans test_api.py pour tester un autre endpoint, par exemple l‚Äôendpoint /docs (documentation Swagger) qui devrait toujours √™tre accessible. python     def test_docs_endpoint():         """Test que la documentation Swagger est accessible"""         response = client.get("/docs")         assert response.status_code == 200

Faites un commit de ce changement : bash     git add tests/test_api.py     git commit -m "test: add docs endpoint test"

Poussez le commit sur la branche main : bash     git push origin main

Observez le pipeline s‚Äôex√©cuter automatiquement dans l‚Äôonglet Actions de votre d√©p√¥t GitHub.

Une fois le workflow termin√© avec succ√®s, v√©rifiez que votre application a bien √©t√© red√©ploy√©e en visitant son URL (celle affich√©e √† la fin du job Verify deployment).

7.10 D√©pannage des Erreurs Courantes
Sympt√¥me / Message d‚Äôerreur	Cause la plus probable	Solution
Login failed... Not all parameters are provided in 'creds'	Le secret AZURE_CREDENTIALS n‚Äôa pas le bon format (trop/moins de 4 champs).	Supprimez et recr√©ez le secret avec l‚Äôobjet JSON √† 4 champs exactement (clientId, clientSecret, subscriptionId, tenantId).
Error: ACR login failed... 401 Unauthorized	Les secrets ACR_USERNAME ou ACR_PASSWORD sont incorrects.	R√©g√©n√©rez les mots de passe de votre ACR avec az acr credential renew --name <acr-name> et mettez √† jour les secrets.
√âchec du job build-and-deploy avec Repository not found ou erreur sur az containerapp update.	Les noms dans env: (ACR_NAME, CONTAINER_APP_NAME) ne correspondent pas √† vos ressources.	V√©rifiez les noms exacts avec les commandes de l‚Äô√âtape 5 et corrigez le fichier ci-cd.yml.
Le job test √©choue sur pytest collected 0 items.	Vos fichiers dans tests/ ne sont pas reconnus comme tests.	Assurez-vous que les noms de fonctions commencent par test_. Exemple : def test_health_check():
Le job test √©choue sur list indices must be integers or slices, not tuple.	Erreur dans app/main.py.	Corrigez l‚Äôindexation : remplacez model.predict_proba(...)[0, 1] par model.predict_proba(...)[0][1].
7.11 Checkpoint
Validation Module 5
Avant de passer au module suivant, v√©rifiez que ces conditions sont remplies :

Le d√©p√¥t GitHub bank-churn-mlops existe et est li√© √† votre projet local.
Les trois secrets GitHub (AZURE_CREDENTIALS, ACR_USERNAME, ACR_PASSWORD) sont cr√©√©s avec les bonnes valeurs et le bon format.
Le fichier .github/workflows/ci-cd.yml est pr√©sent dans votre projet et contient les noms exacts de vos ressources Azure.
Le pipeline CI/CD s‚Äôex√©cute sans erreur dans l‚Äôonglet GitHub Actions (les jobs test et build-and-deploy sont verts ‚úÖ).
L‚Äôapplication se red√©ploie automatiquement : apr√®s un git push, une nouvelle image est cr√©√©e et votre API conteneuris√©e est mise √† jour sur Azure.
8 Module 6 : Monitoring et Maintenance
8.1 Objectif
Mettre en place le monitoring de l‚Äôapplication en production, suivre l‚Äô√©tat de l‚ÄôAPI, les performances et d√©tecter le data drift √† l‚Äôaide d‚ÄôAzure Application Insights.

8.2 Configuration Application Insights
# Cr√©ation d'Application Insights
az monitor app-insights component create \
  --app bank-churn-insights \
  --location $LOCATION \
  --resource-group $RESOURCE_GROUP \
  --application-type web

# R√©cup√©ration de la connection string
APPINSIGHTS_CONN=$(az monitor app-insights component show \
  --app bank-churn-insights \
  --resource-group $RESOURCE_GROUP \
  --query connectionString -o tsv)

echo "Connection String : $APPINSIGHTS_CONN"

# Injection de la variable d'environnement dans Azure Container Apps
az containerapp update \
  --name $CONTAINER_APP_NAME \
  --resource-group $RESOURCE_GROUP \
  --set-env-vars "APPLICATIONINSIGHTS_CONNECTION_STRING=$APPINSIGHTS_CONN"

8.3 Int√©gration du Monitoring dans le Code
8.3.1 D√©pendances
Ajoutez dans requirements.txt :

opencensus-ext-azure==1.1.9
opencensus-ext-requests==0.12.1

8.4 Instrumentation de l‚ÄôAPI FastAPI (app/main.py)
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import joblib
import numpy as np
import logging
import os
import traceback

from opencensus.ext.azure.log_exporter import AzureLogHandler
from app.models import CustomerFeatures, PredictionResponse, HealthResponse
from app.drift_detect import detect_drift

# -------------------------------------------------
# Logging & Application Insights
# -------------------------------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("bank-churn-api")

APPINSIGHTS_CONN = os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
if APPINSIGHTS_CONN:
    logger.addHandler(AzureLogHandler(connection_string=APPINSIGHTS_CONN))
    logger.info("Application Insights connect√©")
else:
    logger.warning("Application Insights non configur√©")

# -------------------------------------------------
# Initialisation FastAPI
# -------------------------------------------------
app = FastAPI(
    title="Bank Churn Prediction API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# -------------------------------------------------
# Chargement du mod√®le
# -------------------------------------------------
MODEL_PATH = os.getenv("MODEL_PATH", "model/churn_model.pkl")
model = None

@app.on_event("startup")
async def load_model():
    global model
    try:
        model = joblib.load(MODEL_PATH)
        logger.info(f"Mod√®le charg√© depuis {MODEL_PATH}")
    except Exception as e:
        logger.error(f"Erreur chargement mod√®le : {e}")
        model = None

# -------------------------------------------------
# Endpoints g√©n√©raux
# -------------------------------------------------
@app.get("/health", response_model=HealthResponse)
def health():
    if model is None:
        raise HTTPException(status_code=503, detail="Mod√®le non charg√©")
    return {"status": "healthy", "model_loaded": True}

# -------------------------------------------------
# Pr√©diction
# -------------------------------------------------
@app.post("/predict", response_model=PredictionResponse)
def predict(features: CustomerFeatures):
    if model is None:
        raise HTTPException(status_code=503, detail="Mod√®le indisponible")

    try:
        X = np.array([[ 
            features.CreditScore,
            features.Age,
            features.Tenure,
            features.Balance,
            features.NumOfProducts,
            features.HasCrCard,
            features.IsActiveMember,
            features.EstimatedSalary,
            features.Geography_Germany,
            features.Geography_Spain
        ]])

        proba = model.predict_proba(X)[0][1]
        prediction = int(proba > 0.5)

        risk = "Low" if proba < 0.3 else "Medium" if proba < 0.7 else "High"

        logger.info(
            "prediction",
            extra={
                "custom_dimensions": {
                    "event_type": "prediction",
                    "probability": float(proba),
                    "risk_level": risk
                }
            }
        )

        return {
            "churn_probability": round(float(proba), 4),
            "prediction": prediction,
            "risk_level": risk
        }

    except Exception as e:
        logger.error(f"Erreur prediction : {e}")
        raise HTTPException(status_code=500, detail=str(e))

# -------------------------------------------------
# Drift Detection (API)
# -------------------------------------------------
@app.post("/drift/check", tags=["Monitoring"])
def check_drift(threshold: float = 0.05):
    try:
        results = detect_drift(
            reference_file="data/bank_churn.csv",
            production_file="data/production_data.csv",
            threshold=threshold
        )

        drifted = [f for f, r in results.items() if r["drift_detected"]]
        drift_pct = len(drifted) / len(results) * 100

        logger.info(
            "drift_detection",
            extra={
                "custom_dimensions": {
                    "event_type": "drift_detection",
                    "features_analyzed": len(results),
                    "features_drifted": len(drifted),
                    "drift_percentage": drift_pct,
                    "risk_level": "HIGH" if drift_pct > 50 else "MEDIUM" if drift_pct > 20 else "LOW"
                }
            }
        )

        return {
            "status": "success",
            "features_analyzed": len(results),
            "features_drifted": len(drifted)
        }

    except Exception:
        tb = traceback.format_exc()
        logger.error(tb)
        raise HTTPException(status_code=500, detail="Erreur drift detection")

8.5 G√©n√©ration de Donn√©es avec Drift
En environnement r√©el, les donn√©es de production √©voluent progressivement (changement de comportement client, contexte √©conomique, nouvelles offres, etc.).

Afin de tester et valider le syst√®me de monitoring, nous utilisons un script de g√©n√©ration artificielle de donn√©es de production avec drift contr√¥l√© : drift_data_gen.py.

Ce script permet de : - simuler diff√©rents niveaux de drift (faible, moyen, fort) - cr√©er un jeu de donn√©es de production r√©aliste - tester la robustesse du syst√®me de d√©tection - valider le fonctionnement des alertes en production

8.6 Script drift_data_gen.py
import pandas as pd
import numpy as np
import os

def generate_drifted_data(
    reference_file="data/bank_churn.csv",
    output_file="data/production_data.csv",
    drift_level="medium"
):
    """
    G√©n√®re des donn√©es de production avec drift artificiel
    
    drift_level:
    - low    : bruit l√©ger
    - medium : d√©calage significatif
    - high   : changement fort
    """

    os.makedirs("data", exist_ok=True)

    ref = pd.read_csv(reference_file)
    prod = ref.copy()

    np.random.seed(42)

    drift_map = {
        "low": 0.05,
        "medium": 0.15,
        "high": 0.30
    }

    intensity = drift_map.get(drift_level, 0.15)

    drift_features = [
        "CreditScore",
        "Age",
        "Balance",
        "EstimatedSalary"
    ]

    for col in drift_features:
        if col in prod.columns:
            std = prod[col].std()
            prod[col] = prod[col] + np.random.normal(
                loc=std * intensity,
                scale=std * intensity,
                size=len(prod)
            )

    prod.to_csv(output_file, index=False)

    print(f"‚úÖ Donn√©es de production g√©n√©r√©es avec drift '{drift_level}'")
    print(f"üìÅ Fichier : {output_file}")

if __name__ == "__main__":
    generate_drifted_data(drift_level="medium")

8.7 Utilisation
# G√©n√©rer des donn√©es de production avec drift moyen
python drift_data_gen.py

Ce fichier production_data.csv est ensuite utilis√© par l‚Äôendpoint :

POST /drift/check
pour comparer les donn√©es de r√©f√©rence et de production.

8.8 R√¥le dans le pipeline MLOps
√âtape	R√¥le
drift_data_gen.py	Simulation du drift
drift_detect.py	D√©tection statistique
Application Insights	Monitoring & historisation
Alertes Azure	D√©cision op√©rationnelle
8.9 D√©tection de Data Drift
8.9.1 Script app/drift_detect.py
import matplotlib
matplotlib.use("Agg")  # OBLIGATOIRE pour Docker / Azure

import pandas as pd
import numpy as np
from scipy.stats import ks_2samp
import json
import os
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

def detect_drift(reference_file, production_file, threshold=0.05, output_dir="drift_reports"):
    os.makedirs(output_dir, exist_ok=True)

    ref = pd.read_csv(reference_file)
    prod = pd.read_csv(production_file)

    results = {}

    for col in ref.columns:
        if col != "Exited" and col in prod.columns:
            stat, p = ks_2samp(ref[col].dropna(), prod[col].dropna())
            results[col] = {
                "p_value": float(p),
                "statistic": float(stat),
                "drift_detected": bool(p < threshold)
            }

    report_path = f"{output_dir}/drift_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_path, "w") as f:
        json.dump(results, f, indent=2)

    return results