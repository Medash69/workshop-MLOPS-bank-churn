# ğŸ¦ Bank Churn Prediction - MLOps Workshop Complet

[![CI/CD Pipeline](https://github.com/Medash69/workshop-MLOPS-bank-churn/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/Medash69/workshop-MLOPS-bank-churn/actions/workflows/ci-cd.yml)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-009688.svg)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.29.0-FF4B4B.svg)](https://streamlit.io/)
[![Azure](https://img.shields.io/badge/Azure-Container%20Apps-0078D4.svg)](https://azure.microsoft.com/)

---

## ğŸ“‹ Table des MatiÃ¨res

1. [PrÃ©sentation du Projet](#-prÃ©sentation-du-projet)
2. [Architecture](#-architecture)
3. [URLs de Production](#-urls-de-production)
4. [PrÃ©requis](#-prÃ©requis)
5. [Installation ComplÃ¨te](#-installation-complÃ¨te)
6. [EntraÃ®nement du ModÃ¨le](#-entraÃ®nement-du-modÃ¨le)
7. [Lancement de l'Application](#-lancement-de-lapplication)
8. [API FastAPI](#-api-fastapi)
9. [Dashboard Streamlit](#-dashboard-streamlit)
10. [DÃ©tection de Data Drift](#-dÃ©tection-de-data-drift)
11. [Conteneurisation Docker](#-conteneurisation-docker)
12. [DÃ©ploiement Azure](#-dÃ©ploiement-azure)
13. [Pipeline CI/CD GitHub Actions](#-pipeline-cicd-github-actions)
14. [MLflow Tracking](#-mlflow-tracking)
15. [Tests](#-tests)
16. [Structure du Projet](#-structure-du-projet)
17. [Commandes Utiles](#-commandes-utiles)
18. [DÃ©pannage](#-dÃ©pannage)

---

## ğŸ¯ PrÃ©sentation du Projet

Ce projet MLOps complet prÃ©dit le **churn client bancaire** (risque de dÃ©part) en utilisant un modÃ¨le de Machine Learning. Il inclut :

- **ModÃ¨le ML** : Random Forest Classifier avec tracking MLflow
- **API REST** : FastAPI avec endpoints de prÃ©diction
- **Dashboard** : Interface Streamlit interactive
- **Monitoring** : DÃ©tection de data drift
- **CI/CD** : Pipeline automatisÃ© GitHub Actions
- **Cloud** : DÃ©ploiement sur Azure Container Apps

### Contexte Business
Une banque souhaite prÃ©dire quels clients risquent de partir pour proposer des actions de rÃ©tention proactives.

### Dataset
- **10 features** : CreditScore, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Geography_Germany, Geography_Spain
- **Target** : Exited (0 = reste, 1 = part)
- **Taille** : 10,000 clients

---

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub Repo   â”‚â”€â”€â”€â–¶â”‚ GitHub Actions  â”‚â”€â”€â”€â–¶â”‚  Azure ACR      â”‚
â”‚                 â”‚    â”‚   (CI/CD)       â”‚    â”‚  (Container     â”‚
â”‚  - Code         â”‚    â”‚  - Tests        â”‚    â”‚   Registry)     â”‚
â”‚  - Dockerfile   â”‚    â”‚  - Build        â”‚    â”‚                 â”‚
â”‚  - Workflows    â”‚    â”‚  - Deploy       â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚â—€â”€â”€â”€â”‚ Azure Container â”‚â—€â”€â”€â”€â”‚   FastAPI       â”‚
â”‚   Dashboard     â”‚    â”‚     Apps        â”‚    â”‚     API         â”‚
â”‚   :8501         â”‚    â”‚                 â”‚    â”‚    :8000        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒ URLs de Production

| Service | URL |
|---------|-----|
| **ğŸ“Š Dashboard Streamlit** | https://bank-churn-dashboard.ashywater-496e8508.swedencentral.azurecontainerapps.io |
| **ğŸ”Œ API FastAPI** | https://bank-churn.ashywater-496e8508.swedencentral.azurecontainerapps.io |
| **ğŸ“š API Documentation** | https://bank-churn.ashywater-496e8508.swedencentral.azurecontainerapps.io/docs |
| **ğŸ“¦ GitHub Repository** | https://github.com/Medash69/workshop-MLOPS-bank-churn |

---

## ğŸ“¦ PrÃ©requis

### Logiciels Requis

| Logiciel | Version | TÃ©lÃ©chargement |
|----------|---------|----------------|
| Python | 3.9+ | https://www.python.org/downloads/ |
| Git | Latest | https://git-scm.com/downloads |
| Docker Desktop | Latest | https://www.docker.com/products/docker-desktop |
| Azure CLI | Latest | https://docs.microsoft.com/cli/azure/install-azure-cli |
| VS Code | Latest | https://code.visualstudio.com/ |

### VÃ©rification des Installations

```bash
# Python
python --version
# Doit afficher: Python 3.9.x ou supÃ©rieur

# Git
git --version

# Docker
docker --version
docker ps

# Azure CLI
az --version
```

### Comptes NÃ©cessaires

- **GitHub** : https://github.com/signup
- **Azure for Students (100$)** : https://azure.microsoft.com/students

---

## ğŸš€ Installation ComplÃ¨te

### Ã‰tape 1 : Cloner le Repository

```bash
# Cloner le projet
git clone https://github.com/Medash69/workshop-MLOPS-bank-churn.git

# Aller dans le dossier
cd workshop-MLOPS-bank-churn
```

### Ã‰tape 2 : CrÃ©er l'Environnement Virtuel

```bash
# CrÃ©er l'environnement virtuel
python -m venv venv

# Activer l'environnement (Windows PowerShell)
.\venv\Scripts\Activate.ps1

# Activer l'environnement (Windows CMD)
venv\Scripts\activate.bat

# Activer l'environnement (Linux/Mac)
source venv/bin/activate
```

### Ã‰tape 3 : Installer les DÃ©pendances

```bash
# Mettre Ã  jour pip
pip install --upgrade pip

# Installer toutes les dÃ©pendances
pip install -r requirements.txt
```

### Ã‰tape 4 : GÃ©nÃ©rer les DonnÃ©es (si nÃ©cessaire)

```bash
# GÃ©nÃ©rer le dataset synthÃ©tique
python generate_data.py
```

---

## ğŸ“ EntraÃ®nement du ModÃ¨le

### Lancer l'EntraÃ®nement

```bash
# EntraÃ®ner le modÃ¨le Random Forest
python train_model.py
```

### RÃ©sultat Attendu

```
Chargement des donnees...
Dataset : 10000 lignes, 11 colonnes
Taux de churn : 23.45%

Train : 8000 lignes
Test : 2000 lignes

Entrainement du modele...

==================================================
RESULTATS DE L'ENTRAINEMENT
==================================================
Accuracy  : 0.8650
Precision : 0.7823
Recall    : 0.6542
F1 Score  : 0.7125
ROC AUC   : 0.8934
==================================================

Modele sauvegarde dans : model/churn_model.pkl
MLflow UI : mlflow ui --port 5000
```

### Visualiser les ExpÃ©riences MLflow

```bash
# Lancer l'interface MLflow
mlflow ui --port 5000

# Ouvrir dans le navigateur
# http://localhost:5000
```

---

## â–¶ï¸ Lancement de l'Application

### Option 1 : Mode Local Simple (RecommandÃ© pour le dÃ©veloppement)

```bash
# Terminal 1 : Lancer l'API FastAPI
uvicorn app.main:app --reload --port 8000

# Terminal 2 : Lancer le Dashboard Streamlit
streamlit run streamlit_app.py --server.port 8501
```

### Option 2 : Utiliser les Scripts de Lancement

**Windows (PowerShell ou CMD) :**
```batch
# Lancer API + Dashboard
start.bat local

# Lancer uniquement l'API
start.bat api-only

# Lancer uniquement le Dashboard
start.bat streamlit-only
```

**Linux/Mac :**
```bash
# Rendre le script exÃ©cutable
chmod +x start.sh

# Lancer API + Dashboard
./start.sh local

# Lancer uniquement l'API
./start.sh api-only

# Lancer uniquement le Dashboard
./start.sh streamlit-only
```

### Option 3 : Avec Docker Compose

```bash
# Construire et lancer tous les services
docker-compose up --build

# Lancer en arriÃ¨re-plan
docker-compose up --build -d

# ArrÃªter les services
docker-compose down
```

### URLs Locales

| Service | URL |
|---------|-----|
| API FastAPI | http://localhost:8000 |
| API Documentation (Swagger) | http://localhost:8000/docs |
| API Documentation (ReDoc) | http://localhost:8000/redoc |
| Dashboard Streamlit | http://localhost:8501 |
| MLflow UI | http://localhost:5000 |

---

## ğŸ”Œ API FastAPI

### Endpoints Disponibles

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/` | Informations sur l'API |
| GET | `/health` | Health check |
| POST | `/predict` | PrÃ©diction simple |
| POST | `/predict/batch` | PrÃ©dictions en lot |
| POST | `/drift/check` | VÃ©rification du drift |

### Exemple : Health Check

```bash
curl http://localhost:8000/health
```

**RÃ©ponse :**
```json
{
  "status": "healthy",
  "is_model_active": true
}
```

### Exemple : PrÃ©diction Simple

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
  }'
```

**RÃ©ponse :**
```json
{
  "churn_probability": 0.2345,
  "prediction": 0,
  "risk_level": "Low"
}
```

### Exemple avec Python

```python
import requests

url = "http://localhost:8000/predict"
data = {
    "CreditScore": 650,
    "Age": 35,
    "Tenure": 5,
    "Balance": 50000,
    "NumOfProducts": 2,
    "HasCrCard": 1,
    "IsActiveMember": 1,
    "EstimatedSalary": 75000,
    "Geography_Germany": 0,
    "Geography_Spain": 1
}

response = requests.post(url, json=data)
print(response.json())
```

### VÃ©rification du Drift

```bash
curl -X POST "http://localhost:8000/drift/check?threshold=0.05"
```

---

## ğŸ“Š Dashboard Streamlit

Le dashboard offre 5 pages interactives :

### 1. ğŸ¯ PrÃ©diction
- Formulaire interactif pour entrer les caractÃ©ristiques client
- Affichage de la probabilitÃ© de churn
- Jauge visuelle du risque
- Recommandations personnalisÃ©es

### 2. ğŸ“Š Exploration des DonnÃ©es
- Statistiques descriptives
- Distribution du churn
- Histogrammes par feature
- Matrice de corrÃ©lation

### 3. âš ï¸ DÃ©tection de Drift
- Analyse des changements de distribution
- Test de Kolmogorov-Smirnov
- Visualisation comparative
- Alertes et recommandations

### 4. ğŸ“ˆ MÃ©triques du ModÃ¨le
- Accuracy, Precision, Recall, F1, ROC AUC
- Historique des entraÃ®nements MLflow
- Matrice de confusion
- Feature importance

### 5. ğŸ”§ Configuration
- Ã‰tat des services (API, modÃ¨le)
- Actions de maintenance
- GÃ©nÃ©ration de donnÃ©es de test

---

## âš ï¸ DÃ©tection de Data Drift

### Utilisation via Python

```python
from app.drift_detect import DriftDetector
import pandas as pd

# Initialiser le dÃ©tecteur
detector = DriftDetector(threshold=0.05)

# Charger les donnÃ©es
ref_data = pd.read_csv("data/bank_churn.csv")
prod_data = pd.read_csv("data/production_data.csv")

# DÃ©tecter le drift
results = detector.detect_all(ref_data, prod_data)

# GÃ©nÃ©rer le rapport
report = detector.generate_report(results)

print(f"Risk Level: {report['summary']['risk_level']}")
print(f"Drifted Features: {report['summary']['drifted_features']}")
```

### GÃ©nÃ©rer des DonnÃ©es de Production SimulÃ©es

```python
from app.drift_detect import generate_drift_data

generate_drift_data(
    reference_file="data/bank_churn.csv",
    output_file="data/production_data.csv",
    drift_features={
        "Age": {"shift": 5, "scale": 1.0},
        "Balance": {"shift": 0, "scale": 1.2},
        "CreditScore": {"shift": -30, "scale": 1.0}
    }
)
```

---

## ğŸ³ Conteneurisation Docker

### Construire l'Image de l'API

```bash
# Construire l'image
docker build -t bank-churn-api:v1 .

# VÃ©rifier l'image
docker images bank-churn-api

# Lancer le conteneur
docker run -d -p 8000:8000 --name churn-api bank-churn-api:v1

# Voir les logs
docker logs churn-api

# ArrÃªter et supprimer
docker stop churn-api
docker rm churn-api
```

### Construire l'Image Streamlit

```bash
# Construire l'image Streamlit
docker build -f Dockerfile.streamlit -t bank-churn-streamlit:v1 .

# Lancer le conteneur
docker run -d -p 8501:8501 --name churn-dashboard bank-churn-streamlit:v1
```

### Docker Compose (Tous les Services)

```bash
# Construire et lancer
docker-compose up --build

# Lancer en arriÃ¨re-plan
docker-compose up -d

# Voir les logs
docker-compose logs -f

# ArrÃªter
docker-compose down

# ArrÃªter et supprimer les volumes
docker-compose down -v
```

---

## â˜ï¸ DÃ©ploiement Azure

### Configuration Azure

| Ressource | Valeur |
|-----------|--------|
| Resource Group | `rg-nlp-deployment` |
| Container Registry (ACR) | `mlopsashash` |
| Container Apps Environment | `env-nlp` |
| API Container App | `bank-churn` |
| Dashboard Container App | `bank-churn-dashboard` |
| RÃ©gion | `swedencentral` |

### Commandes Azure CLI

#### Connexion Ã  Azure

```bash
# Se connecter
az login

# VÃ©rifier l'abonnement
az account show

# Lister les ressources
az group list -o table
```

#### GÃ©rer le Container Registry

```bash
# Se connecter Ã  l'ACR
az acr login --name mlopsashash

# Lister les images
az acr repository list --name mlopsashash -o table

# Voir les tags d'une image
az acr repository show-tags --name mlopsashash --repository bank-churn-api
```

#### GÃ©rer les Container Apps

```bash
# Lister les Container Apps
az containerapp list --resource-group rg-nlp-deployment -o table

# Voir les logs de l'API
az containerapp logs show \
  --name bank-churn \
  --resource-group rg-nlp-deployment \
  --tail 100

# Voir les logs du Dashboard
az containerapp logs show \
  --name bank-churn-dashboard \
  --resource-group rg-nlp-deployment \
  --tail 100

# RedÃ©marrer une app
az containerapp revision restart \
  --name bank-churn \
  --resource-group rg-nlp-deployment

# Obtenir l'URL
az containerapp show \
  --name bank-churn \
  --resource-group rg-nlp-deployment \
  --query properties.configuration.ingress.fqdn -o tsv
```

#### DÃ©ploiement Manuel

```bash
# Build et push de l'image
docker build -t mlopsashash.azurecr.io/bank-churn-api:latest .
az acr login --name mlopsashash
docker push mlopsashash.azurecr.io/bank-churn-api:latest

# Mettre Ã  jour la Container App
az containerapp update \
  --name bank-churn \
  --resource-group rg-nlp-deployment \
  --image mlopsashash.azurecr.io/bank-churn-api:latest
```

---

## ğŸ”„ Pipeline CI/CD GitHub Actions

### Secrets GitHub Ã  Configurer

Allez sur : **https://github.com/Medash69/workshop-MLOPS-bank-churn/settings/secrets/actions**

| Secret | Description |
|--------|-------------|
| `AZURE_CREDENTIALS` | JSON du Service Principal Azure |
| `ACR_USERNAME` | Username du Container Registry (`mlopsashash`) |
| `ACR_PASSWORD` | Password du Container Registry |

### CrÃ©er le Service Principal Azure

```bash
az ad sp create-for-rbac \
  --name "github-mlops-sp" \
  --role contributor \
  --scopes /subscriptions/924feefb-f89f-423a-a62f-3d81583d01da \
  --json-auth
```

### RÃ©cupÃ©rer les Credentials ACR

```bash
# Username
az acr credential show --name mlopsashash --query username -o tsv

# Password
az acr credential show --name mlopsashash --query "passwords[0].value" -o tsv
```

### Structure du Pipeline

```yaml
# .github/workflows/ci-cd.yml

Jobs:
1. test                        # ExÃ©cute pytest avec couverture
2. build-and-deploy-api        # Build et dÃ©ploie l'API
3. build-and-deploy-streamlit  # Build et dÃ©ploie Streamlit
```

### DÃ©clencheurs

- **Push sur main** : DÃ©ploiement automatique
- **Pull Request** : Tests uniquement
- **Manual** : Via workflow_dispatch

### Relancer le Pipeline Manuellement

1. Aller sur **Actions** dans GitHub
2. Cliquer sur **CI/CD Pipeline**
3. Cliquer sur **Run workflow**

---

## ğŸ“ˆ MLflow Tracking

### Lancer l'Interface MLflow

```bash
mlflow ui --port 5000
```

### Voir les ExpÃ©riences

```python
import mlflow

# Configurer le tracking
mlflow.set_tracking_uri("./mlruns")

# Lister les expÃ©riences
experiments = mlflow.search_experiments()
for exp in experiments:
    print(f"{exp.name}: {exp.experiment_id}")

# Lister les runs
runs = mlflow.search_runs(experiment_ids=["159076234787646138"])
print(runs[['run_id', 'metrics.accuracy', 'metrics.f1_score']])
```

### Charger un ModÃ¨le depuis MLflow

```python
import mlflow.sklearn

# Charger le modÃ¨le enregistrÃ©
model = mlflow.sklearn.load_model("models:/bank-churn-classifier/latest")

# Faire une prÃ©diction
prediction = model.predict([[650, 35, 5, 50000, 2, 1, 1, 75000, 0, 1]])
```

---

## ğŸ§ª Tests

### ExÃ©cuter Tous les Tests

```bash
# Tests simples
pytest tests/ -v

# Tests avec couverture
pytest tests/ -v --cov=app --cov-report=term

# Rapport HTML de couverture
pytest tests/ -v --cov=app --cov-report=html

# Ouvrir le rapport (Windows)
start htmlcov/index.html

# Ouvrir le rapport (Mac)
open htmlcov/index.html
```

### Structure des Tests

```
tests/
â”œâ”€â”€ test_api.py           # Tests des endpoints API
â”œâ”€â”€ test_model.py         # Tests du modÃ¨le ML (Ã  crÃ©er)
â””â”€â”€ test_drift.py         # Tests de dÃ©tection de drift (Ã  crÃ©er)
```

---

## ğŸ“ Structure du Projet

```
bank-churn-mlops/
â”‚
â”œâ”€â”€ ğŸ“‚ .github/
â”‚   â””â”€â”€ ğŸ“‚ workflows/
â”‚       â””â”€â”€ ci-cd.yml              # Pipeline CI/CD
â”‚
â”œâ”€â”€ ğŸ“‚ app/                        # Code de l'API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # Endpoints FastAPI
â”‚   â”œâ”€â”€ models.py                  # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ drift_detect.py            # DÃ©tection de drift
â”‚   â”œâ”€â”€ drift_data_gen.py          # GÃ©nÃ©ration de donnÃ©es
â”‚   â””â”€â”€ utils.py                   # Fonctions utilitaires
â”‚
â”œâ”€â”€ ğŸ“‚ data/                       # DonnÃ©es
â”‚   â”œâ”€â”€ bank_churn.csv             # Dataset d'entraÃ®nement
â”‚   â””â”€â”€ production_data.csv        # DonnÃ©es de production
â”‚
â”œâ”€â”€ ğŸ“‚ model/                      # ModÃ¨les sauvegardÃ©s
â”‚   â””â”€â”€ churn_model.pkl            # ModÃ¨le Random Forest
â”‚
â”œâ”€â”€ ğŸ“‚ mlruns/                     # ExpÃ©riences MLflow
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                      # Tests unitaires
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ ğŸ“‚ drift_reports/              # Rapports de drift
â”‚   â””â”€â”€ *.json
â”‚
â”œâ”€â”€ ğŸ“„ streamlit_app.py            # Dashboard Streamlit
â”œâ”€â”€ ğŸ“„ train_model.py              # Script d'entraÃ®nement
â”œâ”€â”€ ğŸ“„ generate_data.py            # GÃ©nÃ©ration du dataset
â”‚
â”œâ”€â”€ ğŸ³ Dockerfile                  # Image Docker API
â”œâ”€â”€ ğŸ³ Dockerfile.streamlit        # Image Docker Streamlit
â”œâ”€â”€ ğŸ³ docker-compose.yml          # Orchestration Docker
â”œâ”€â”€ ğŸ³ .dockerignore               # Fichiers ignorÃ©s par Docker
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ start.bat                   # Script Windows
â”œâ”€â”€ ğŸ“„ start.sh                    # Script Linux/Mac
â”œâ”€â”€ ğŸ“„ .gitignore                  # Fichiers ignorÃ©s par Git
â””â”€â”€ ğŸ“„ README.md                   # Ce fichier
```

---

## ğŸ›  Commandes Utiles

### Commandes de DÃ©marrage Rapide

```bash
# 1. Cloner le projet
git clone https://github.com/Medash69/workshop-MLOPS-bank-churn.git
cd workshop-MLOPS-bank-churn

# 2. CrÃ©er et activer l'environnement virtuel
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows PowerShell

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. EntraÃ®ner le modÃ¨le
python train_model.py

# 5. Lancer l'API (Terminal 1)
uvicorn app.main:app --reload --port 8000

# 6. Lancer le Dashboard (Terminal 2)
streamlit run streamlit_app.py --server.port 8501
```

### Git

```bash
# Voir le statut
git status

# Ajouter tous les fichiers
git add -A

# Committer
git commit -m "votre message"

# Pousser sur GitHub
git push origin main

# RÃ©cupÃ©rer les derniÃ¨res modifications
git pull origin main
```

### Python/Pip

```bash
# Installer les dÃ©pendances
pip install -r requirements.txt

# Mettre Ã  jour une dÃ©pendance
pip install --upgrade <package>

# Sauvegarder les dÃ©pendances
pip freeze > requirements.txt
```

### Docker

```bash
# Lister les conteneurs
docker ps -a

# Lister les images
docker images

# Supprimer un conteneur
docker rm <container_id>

# Supprimer une image
docker rmi <image_id>

# Nettoyer les ressources inutilisÃ©es
docker system prune -a
```

### Azure

```bash
# Se connecter
az login

# Voir les logs
az containerapp logs show --name bank-churn --resource-group rg-nlp-deployment --tail 50

# RedÃ©marrer l'app
az containerapp revision restart --name bank-churn --resource-group rg-nlp-deployment
```

---

## ğŸ”§ DÃ©pannage

### ProblÃ¨me : Le modÃ¨le n'est pas trouvÃ©

```bash
# Solution : EntraÃ®ner le modÃ¨le
python train_model.py
```

### ProblÃ¨me : L'API ne rÃ©pond pas

```bash
# VÃ©rifier si le port est utilisÃ©
netstat -ano | findstr :8000

# Tuer le processus (Windows)
taskkill /PID <PID> /F

# Relancer l'API
uvicorn app.main:app --reload --port 8000
```

### ProblÃ¨me : Erreur Docker "port already in use"

```bash
# ArrÃªter tous les conteneurs
docker stop $(docker ps -aq)

# Relancer
docker-compose up --build
```

### ProblÃ¨me : Tests Ã©chouent

```bash
# VÃ©rifier que le modÃ¨le existe
python train_model.py

# Relancer les tests
pytest tests/ -v
```

### ProblÃ¨me : DÃ©ploiement Azure Ã©choue

```bash
# VÃ©rifier les secrets GitHub
# https://github.com/Medash69/workshop-MLOPS-bank-churn/settings/secrets/actions

# VÃ©rifier la connexion Azure
az login
az account show

# VÃ©rifier l'ACR
az acr login --name mlopsashash
```

---

## ğŸ“ Variables d'Environnement

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `MODEL_PATH` | Chemin vers le modÃ¨le | `model/churn_model.pkl` |
| `API_URL` | URL de l'API FastAPI | `http://localhost:8000` |
| `APPLICATIONINSIGHTS_CONNECTION_STRING` | Azure App Insights | - |

---

## ğŸ“Š MÃ©triques du ModÃ¨le

| MÃ©trique | Valeur |
|----------|--------|
| Accuracy | ~0.86 |
| Precision | ~0.78 |
| Recall | ~0.65 |
| F1 Score | ~0.71 |
| ROC AUC | ~0.89 |

---

## ğŸ‘¨â€ğŸ’» Auteur

**Workshop MLOps avec Azure**
- GitHub : https://github.com/Medash69

---

## ğŸ“„ Licence

Ce projet est sous licence MIT.

---

## ğŸ™ Remerciements

- FastAPI pour le framework API
- Streamlit pour le dashboard
- MLflow pour le tracking
- Azure pour l'hÃ©bergement cloud
- Scikit-learn pour le modÃ¨le ML

---

**DerniÃ¨re mise Ã  jour :** Janvier 2026
